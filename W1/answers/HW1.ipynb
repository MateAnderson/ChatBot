{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirements:\n",
    "#Python 3.9.5>\n",
    "#pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7wK6pVaD6sz",
    "outputId": "97f13015-45b7-45cf-ebed-331639bc3562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIkw6bvv-haP"
   },
   "source": [
    "## Table of content for theory: \n",
    "\n",
    "1.  N-gram concept usecase\n",
    "        1.1. n-gram\n",
    "        1.1. computing \"joint probability with conditional probability\" \n",
    "        1.3. Markof assumption \n",
    "2. How efficiently store N-grams ?\n",
    "3. How efficiently find all 1,2,...,n-grams ?\n",
    "\n",
    "4.  N-gram as a Language Model\n",
    "        4.1. Blank Completion ( text __  / text __ text )\n",
    "        4.2. Finding Probability of occurence of a sentence\n",
    "5. Possible drawbacks of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content for hands-on: \n",
    "\n",
    "1.  Implementation of functions\n",
    "2.  Driver code\n",
    "    1. Question 1 and 2 answers\n",
    "    2. Question3 \n",
    "    3. Question4\n",
    "    4. Question5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "nv4o34qR-iFr",
    "outputId": "d3e4b0d5-b20d-43a3-cc54-060a76d740ac"
   },
   "outputs": [],
   "source": [
    "# Assumption: Corpus can fit in RAM and we don't need to read and store it line by line+\n",
    "\n",
    "def load_data(address):\n",
    "    # load strings and process them finally -->\n",
    "    # return a list of list containing tokens\n",
    "    sentences = []\n",
    "    with open(address, \"r\",encoding=\"utf-8\") as file:\n",
    "        # := is a new feature in py3.8 called walrus operator \n",
    "        # https://docs.python.org/3/whatsnew/3.8.html#assignment-expressions\n",
    "        while line := file.readline():\n",
    "            processed = preprocessing(line) \n",
    "            if not processed == -1:\n",
    "                # note: appending a list is amortized O(1)\n",
    "                # so, we don't need to be worried about it\n",
    "                sentences.append(processed)\n",
    "    return sentences\n",
    "\n",
    "def preprocessing(string):\n",
    "    res = string.rstrip().lstrip().split()\n",
    "    return res if len(res)>3 else -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accum_ngram(corp , n_gram = 5):\n",
    "    \n",
    "    # Python dictionary has dynamic hashing and can access each key's value in O(1) time.\n",
    "    # It, however, needs O(n) space to store n strings. \"Trie\" is an attempt to reduce \n",
    "    # this space complexity\n",
    "    \n",
    "    # accumulated n-grams \n",
    "    # by accumulated I mean we compute all n-grams from 1 up to n\n",
    "    # Result will be stored and returned as a trie, implemented with python dictionary\n",
    "    \n",
    "    n_grams = {}\n",
    "    n_grams['#'] = 0 \n",
    "    for stc in corp:\n",
    "        n = len(stc)\n",
    "        n_grams['#'] += n # update total words count\n",
    "        for token_idx in range(n):\n",
    "            dict_ptr = n_grams\n",
    "            for next_token_idx in range(token_idx,n):\n",
    "                if next_token_idx - token_idx >= n_gram:\n",
    "                    break\n",
    "                #print(f'token_idx:{token_idx}, next_token_idx:{next_token_idx},the word:{stc[next_token_idx]}')\n",
    "                if not stc[next_token_idx] in dict_ptr:\n",
    "                    dict_ptr[stc[next_token_idx]] = {'#':0}\n",
    "                    \n",
    "                dict_ptr[stc[next_token_idx]]['#'] = dict_ptr[stc[next_token_idx]]['#'] + 1\n",
    "                dict_ptr = dict_ptr[stc[next_token_idx]]\n",
    "                \n",
    "            \n",
    "    return n_grams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "tsx_Irph-rlW"
   },
   "outputs": [],
   "source": [
    "def count_finder(sentence, n_grams_dict, j, i):\n",
    "    # find both numerator and numerator \n",
    "    ptr_dict = n_grams_dict\n",
    "    \n",
    "    for k in range(j,i):\n",
    "        ptr_dict = ptr_dict[sentence[k]]\n",
    "\n",
    "    return ptr_dict[sentence[i]]['#'], ptr_dict['#']\n",
    "\n",
    "def occurance_probability(sentence, n_grams_dict, n_gram = 2):\n",
    "    if n_gram ==1:\n",
    "        prob = 1\n",
    "        for token in sentence:\n",
    "            prob *= n_grams_dict[token]['#']\n",
    "        prob *= (1/(n_grams_dict['#']**len(sentence)))\n",
    "        return prob\n",
    "    \n",
    "    # n_gram is the numeber of previous words each conditional probability depends on\n",
    "    # sentence: list of tokens\n",
    "    \n",
    "    # handeling the first fraction separately\n",
    "    prob = n_grams_dict[sentence[0]]['#']/n_grams_dict['#'] \n",
    "    \n",
    "    for i in range(1,len(sentence)):\n",
    "        j = i - (n_gram -1) if (i-n_gram>=0) else 0\n",
    "        numerator, denumerator =count_finder(sentence=sentence, n_grams_dict=n_grams_dict, j = j, i = i)\n",
    "        prob *= (numerator/denumerator)\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "AHZII8SD-r4K"
   },
   "outputs": [],
   "source": [
    "def dfs(ptr_dict, current_str, remained_depth, counts_ls, terms_ls):\n",
    "    if remained_depth == 1:\n",
    "        keys = list(ptr_dict.keys())\n",
    "        keys.pop(0) # first key is '#'\n",
    "        for key in keys:\n",
    "            s = current_str + ' ' + key # we gotta remove first ' '\n",
    "            terms_ls.append(s[1:])\n",
    "            counts_ls.append(ptr_dict[key]['#'])\n",
    "    else:\n",
    "        keys = list(ptr_dict.keys())\n",
    "        keys.pop(0)\n",
    "        for key in keys:\n",
    "            dfs(ptr_dict= ptr_dict[key],current_str = current_str+' '+key,\n",
    "                remained_depth =remained_depth-1,counts_ls = counts_ls, terms_ls=terms_ls)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "9Y5yj14i-r7c"
   },
   "outputs": [],
   "source": [
    "# Visualize different n_grams with tables\n",
    "\n",
    "def visual(n_grams_dict, n_gram ):\n",
    "    # n_gram dicts contains all n grams in a trie data structure\n",
    "    # we convert trie structure into pandas df\n",
    "    import pandas as pd\n",
    "    counts = []\n",
    "    terms = []\n",
    "    dfs(n_grams_dict, current_str = '', remained_depth = n_gram,\n",
    "            counts_ls = counts, terms_ls = terms)\n",
    "    \n",
    "    # tabularizing\n",
    "    n  = sum(counts)\n",
    "    size = len(terms)\n",
    "    df = pd.DataFrame({'terms':terms})\n",
    "    df['counts'] = counts\n",
    "    df.sort_values(by=['counts'], inplace=True, ascending=False,ignore_index=True)\n",
    "    df['freq'] = df['counts'].apply(lambda x: x/n)\n",
    "    df['freq_index'] = df['freq'] * [i for i in range(1,size+1)]\n",
    "    return df\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3handler(string):\n",
    "    grams_prob =[-1,-1,-1] #-1 means \"error raised\"\n",
    "    s0 = preprocessing(string)\n",
    "    for i in range(0,3):\n",
    "        try:\n",
    "            grams_prob[i] = occurance_probability(s0, accum_five_gram, i+1)\n",
    "        except:\n",
    "            pass\n",
    "    print(f'For this sentence: {string} we have: \\n1_gram_prob:{grams_prob[0]}\\n2_gram_prob:{grams_prob[1]}\\n3_gram_prob:{grams_prob[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5handler(string,df):\n",
    "    indices = []\n",
    "    s = preprocessing(string)\n",
    "    last_token =  s[-1]\n",
    "    n = len(s[-1])\n",
    "    df_ln = df.shape[0]\n",
    "    for i in range(df_ln):\n",
    "        if df['terms'].values[i][:n] == last_token and df['terms'].values[i][n] == ' ':\n",
    "            indices.append(i)\n",
    "    print(f'The sentence: {string} can be completed with bigrams in the following way:\\n')\n",
    "    option1 = string + df['terms'][indices[0]][n:] \n",
    "    option2 = string + df['terms'][indices[1]][n:]\n",
    "    print(f'First way for completing: {option1}') \n",
    "    print(f'Second way for completing: {option2}\\n')\n",
    "    return df.loc[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkalMU28-0gy"
   },
   "source": [
    "### Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "wTpfKYdj-2hR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['زانک', 'دل', 'یا', 'اوست', 'یا', 'خود', 'اوست', 'دل'],\n",
       " ['عکس', 'هر', 'نقشی', 'نتابد', 'تا', 'ابد'],\n",
       " ['پیروز', 'شد', 'از', 'طلعت', 'او', 'دولت', 'و', 'اختر'],\n",
       " ['ای', 'تیغ', 'گهردار', 'تو', 'از', 'فتح', 'مرکب'],\n",
       " ['باز', 'رویاند', 'گل', 'صباغ', 'را'],\n",
       " ['کای', 'بسوزیده', 'برون', 'آ', 'تازه', 'شو'],\n",
       " ['سینه', 'شیرین', 'خبر', 'دارد', 'ز', 'خسرو', 'بس', 'بود'],\n",
       " ['ناله', 'گردون', 'کفایت', 'باشد', 'از', 'تقدیر', 'بار'],\n",
       " ['بریاد', 'بط', 'باده', 'دوانست', 'بهر', 'در'],\n",
       " ['شعرش', 'همه', 'ژاژست', 'وکلامش', 'همه', 'یاوه']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_sentences = load_data(\"train.txt\")\n",
    "loaded_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to Q1 and Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "mhuLtsfx-5ml"
   },
   "outputs": [],
   "source": [
    "accum_one_gram = accum_ngram(loaded_sentences , n_gram = 1)\n",
    "accum_two_gram = accum_ngram(loaded_sentences , n_gram = 2)\n",
    "#accum_three_gram = accum_ngram(loaded_sentences , n_gram = 3)\n",
    "accum_five_gram = accum_ngram(loaded_sentences , n_gram = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "8wDJqxOv-5rI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>و</td>\n",
       "      <td>50912</td>\n",
       "      <td>0.038950</td>\n",
       "      <td>0.038950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>از</td>\n",
       "      <td>31178</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>0.047705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>به</td>\n",
       "      <td>30037</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.068939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>که</td>\n",
       "      <td>26787</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>0.081973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>در</td>\n",
       "      <td>23525</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>0.089988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  terms  counts      freq  freq_index\n",
       "0     و   50912  0.038950    0.038950\n",
       "1    از   31178  0.023852    0.047705\n",
       "2    به   30037  0.022980    0.068939\n",
       "3    که   26787  0.020493    0.081973\n",
       "4    در   23525  0.017998    0.089988"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = visual(n_grams_dict = accum_five_gram, n_gram = 1) # x_gram accaptable for any x>=1 \n",
    "#d.head(20)\n",
    "d1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>از آن</td>\n",
       "      <td>1394</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>که در</td>\n",
       "      <td>1247</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.002229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>او را</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>را به</td>\n",
       "      <td>1105</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.003951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>که از</td>\n",
       "      <td>1070</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.004782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   terms  counts      freq  freq_index\n",
       "0  از آن    1394  0.001246    0.001246\n",
       "1  که در    1247  0.001115    0.002229\n",
       "2  او را    1123  0.001004    0.003011\n",
       "3  را به    1105  0.000988    0.003951\n",
       "4  که از    1070  0.000956    0.004782"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = visual(n_grams_dict = accum_five_gram, n_gram = 2) # x_gram accaptable for any x>=1 \n",
    "#d.head(20)\n",
    "d2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>می سوزم و می سازم</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>خاک و باد و آب</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ای بی وفا ای پاسبان</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>و باد و آب و</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خبر ده که تا کجاست</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 terms  counts      freq  freq_index\n",
       "0    می سوزم و می سازم      11  0.000020    0.000020\n",
       "1       خاک و باد و آب      10  0.000018    0.000036\n",
       "2  ای بی وفا ای پاسبان      10  0.000018    0.000054\n",
       "3         و باد و آب و      10  0.000018    0.000072\n",
       "4   خبر ده که تا کجاست       8  0.000014    0.000072"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5 = visual(n_grams_dict = accum_five_gram, n_gram = 5) # x_gram accaptable for any x>=1 \n",
    "#d.head(20)\n",
    "d5.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPvnGzUe-5wV"
   },
   "source": [
    "#### Answer to Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this sentence: چون تویی آید به زیبایی و شیرینی پسر we have: \n",
      "1_gram_prob:1.5881306963873775e-24\n",
      "2_gram_prob:2.653444213453881e-19\n",
      "3_gram_prob:7.589683679349442e-11\n",
      "For this sentence: دل در این درد و رنج پاره کنیم we have: \n",
      "1_gram_prob:2.3266120884334263e-22\n",
      "2_gram_prob:2.181627522993893e-18\n",
      "3_gram_prob:2.9968695710428407e-12\n",
      "For this sentence: ای به آرام تو زمین را سنگ we have: \n",
      "1_gram_prob:1.7214192877055589e-18\n",
      "2_gram_prob:1.8831712377608751e-19\n",
      "3_gram_prob:1.9030848628816505e-09\n",
      "For this sentence: جان را زند آ باغ صلاهای تعالوا we have: \n",
      "1_gram_prob:7.222886310676774e-27\n",
      "2_gram_prob:5.342423098525576e-16\n",
      "3_gram_prob:1.5300802297568475e-07\n",
      "For this sentence: شاهد و شمع و شراب و مطرب آنجا بهترست we have: \n",
      "1_gram_prob:2.261582778132732e-28\n",
      "2_gram_prob:5.72150764844012e-22\n",
      "3_gram_prob:2.709236115708343e-11\n",
      "For this sentence: شب است و شمع و شراب و شیرینی we have: \n",
      "1_gram_prob:1.6337996873326272e-21\n",
      "2_gram_prob:3.3462669538796835e-19\n",
      "3_gram_prob:-1\n"
     ]
    }
   ],
   "source": [
    "inp = [\"چون تویی آید به زیبایی و شیرینی پسر\",\"دل در این درد و رنج پاره کنیم\",\"ای به آرام تو زمین را سنگ\",\"جان را زند آ باغ صلاهای تعالوا\",\"شاهد و شمع و شراب و مطرب آنجا بهترست\",\"شب است و شمع و شراب و شیرینی\"]\n",
    "for sentence in inp:\n",
    "    question3handler(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edj3hH1j-54Y"
   },
   "source": [
    "#### Answer to Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stx = 'شب است و شمع و شراب و شیرینی'\n",
    "\n",
    "Why we cannot find occurrence of stx? \n",
    "+ one of the reasons coule be: Although we have seen all of the stx's tokens, we have not seen some of its triples\n",
    "\n",
    "To tackle this issue:\n",
    "1. we can replace its probability with the nearest n-gram\n",
    "2. in case we have not seen a toke like شیرینی in our corpus, we can replace شیرینی with the most similar word that we have in our Corpus,can't we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence: چون مشک سیه بود مرا هر دو بنا can be completed with bigrams in the following way:\n",
      "\n",
      "First way for completing: چون مشک سیه بود مرا هر دو بنا گوش\n",
      "Second way for completing: چون مشک سیه بود مرا هر دو بنا و\n",
      "The sentence: گر خورد سوگند هم آن can be completed with bigrams in the following way:\n",
      "\n",
      "First way for completing: گر خورد سوگند هم آن را\n",
      "Second way for completing: گر خورد سوگند هم آن که\n",
      "The sentence: زانک نفس آشفته تر گردد از can be completed with bigrams in the following way:\n",
      "\n",
      "First way for completing: زانک نفس آشفته تر گردد از آن\n",
      "Second way for completing: زانک نفس آشفته تر گردد از تو\n",
      "The sentence: ازین زشت تر در جهان رنگ can be completed with bigrams in the following way:\n",
      "\n",
      "First way for completing: ازین زشت تر در جهان رنگ و\n",
      "Second way for completing: ازین زشت تر در جهان رنگ رنگ\n"
     ]
    }
   ],
   "source": [
    "lst = [\"چون مشک سیه بود مرا هر دو بنا\",\"گر خورد سوگند هم آن\",\"زانک نفس آشفته تر گردد از\",\"ازین زشت تر در جهان رنگ\"]\n",
    "data_frames = []\n",
    "for sent in lst:\n",
    "    data_frames.append(question5handler(sent,d2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>بنا گوش</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.099371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27053</th>\n",
       "      <td>بنا و</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.120908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33723</th>\n",
       "      <td>بنا کرده</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.120574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56693</th>\n",
       "      <td>بنا را</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.152024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56696</th>\n",
       "      <td>بنا کرد</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.152032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          terms  counts      freq  freq_index\n",
       "15881   بنا گوش       7  0.000006    0.099371\n",
       "27053     بنا و       5  0.000004    0.120908\n",
       "33723  بنا کرده       4  0.000004    0.120574\n",
       "56693    بنا را       3  0.000003    0.152024\n",
       "56696   بنا کرد       3  0.000003    0.152032"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>آن را</td>\n",
       "      <td>324</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.022010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>آن که</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.022162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>آن یکی</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.032661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>آن به</td>\n",
       "      <td>159</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.036382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>آن کس</td>\n",
       "      <td>126</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.040319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      terms  counts      freq  freq_index\n",
       "75    آن را     324  0.000290    0.022010\n",
       "76    آن که     322  0.000288    0.022162\n",
       "202  آن یکی     180  0.000161    0.032661\n",
       "255   آن به     159  0.000142    0.036382\n",
       "357   آن کس     126  0.000113    0.040319"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>از آن</td>\n",
       "      <td>1394</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>از تو</td>\n",
       "      <td>779</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.005570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>از پی</td>\n",
       "      <td>612</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.009299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>از این</td>\n",
       "      <td>480</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.013729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>از بهر</td>\n",
       "      <td>463</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.014485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     terms  counts      freq  freq_index\n",
       "0    از آن    1394  0.001246    0.001246\n",
       "7    از تو     779  0.000696    0.005570\n",
       "16   از پی     612  0.000547    0.009299\n",
       "31  از این     480  0.000429    0.013729\n",
       "34  از بهر     463  0.000414    0.014485"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>رنگ و</td>\n",
       "      <td>106</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.044531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>رنگ رنگ</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.084708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5814</th>\n",
       "      <td>رنگ از</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.088360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>رنگ او</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.094062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11134</th>\n",
       "      <td>رنگ است</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.099528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         terms  counts      freq  freq_index\n",
       "469      رنگ و     106  0.000095    0.044531\n",
       "5264   رنگ رنگ      18  0.000016    0.084708\n",
       "5814    رنگ از      17  0.000015    0.088360\n",
       "8094    رنگ او      13  0.000012    0.094062\n",
       "11134  رنگ است      10  0.000009    0.099528"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames[3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYGdS9E0_WGH"
   },
   "source": [
    "# Further Development notes\n",
    "\n",
    "1. df['id'] column is redundent (solved)\n",
    "2. optimize question5hendler function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for your attention\n",
    "# Any feedback or issue is very welcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
