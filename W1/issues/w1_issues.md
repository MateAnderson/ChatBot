1. How we can efficiently find n-grams (from 1 to n) of a massive corpus and how efficiently store them (B-plus tree? Trie? or other data structures) 

2. It seems probability of bigrams are being calculated inaccurately in lab's notebooks.

3. Zipf's law does not hold for a random set. Is there any justification for why it hold within English words frequencies? 

4. utf-8 ?

5. Why maximum likelihood and why not probability?

6. Preplexity
